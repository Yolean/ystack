#!/usr/bin/env bash
[ -z "$DEBUG" ] || set -x
set -e

[ -z "$KUBECONFIG" ] && echo "Provision requires an explicit KUBECONFIG env" && exit 1

[ -z "$VM_NAME" ] && VM_NAME="ystack-master"
[ -z "$VM_RESOURCES" ] && VM_RESOURCES="-m 8G -d 40G -c 4"

if ! multipass info "$VM_NAME" 2>/dev/null
then
  multipass launch -n "$VM_NAME" $VM_RESOURCES
fi

# https://medium.com/@mattiaperi/kubernetes-cluster-with-k3s-and-multipass-7532361affa3
K3S_NODEIP_MASTER="$(multipass info $VM_NAME | grep "IPv4" | awk -F' ' '{print $2}')"

echo "# VM_NAME=\"$VM_NAME\" found. The rest of this script runs inside the VM."

multipass exec "$VM_NAME" -- sudo bash -cex '

swapoff -a
# requires reboot, according to https://askubuntu.com/questions/259739/kswapd0-is-taking-a-lot-of-cpu
echo vm.swappiness=0 | sudo tee -a /etc/sysctl.conf
# this process has been seen eating lots of cpu
kswapd_pid=$(ps aux | grep kswapd | grep -v grep | awk "{ print \$2 }")
top -b -p $kswapd_pid -n 1

export INSTALL_K3S_SKIP_START=true

# For kubectl top to work with metrics-server, https://github.com/rancher/k3s/issues/252#issuecomment-482662774
export INSTALL_K3S_EXEC="--kubelet-arg=address=0.0.0.0"

mkdir -p /etc/rancher/k3s
cat <<EOF >> /etc/rancher/k3s/registries.yaml
mirrors:
  "builds-registry.ystack.svc.cluster.local":
    endpoint:
    - http://builds-registry.ystack.svc.cluster.local
  "prod-registry.ystack.svc.cluster.local":
    endpoint:
    - http://prod-registry.ystack.svc.cluster.local
EOF

INSTALLER_REVISION=e810ee1678dc59ed35970734e69a5b31b5773550
export INSTALL_K3S_VERSION=v0.10.1-rc1
curl -sfL https://github.com/rancher/k3s/raw/$INSTALLER_REVISION/install.sh | sh -

mkdir -p     $K3S_DATA_DIR/agent/etc/containerd
cat <<EOF >> $K3S_DATA_DIR/agent/etc/containerd/config.toml.tmpl
[metrics]
address = "0.0.0.0:1338"

# https://github.com/rancher/k3s/blob/master/pkg/agent/templates/templates.go
[plugins.opt]
  path = "{{ .NodeConfig.Containerd.Opt }}"
[plugins.cri]
  stream_server_address = "127.0.0.1"
  stream_server_port = "10010"
{{- if .IsRunningInUserNS }}
  disable_cgroup = true
  disable_apparmor = true
  restrict_oom_score_adj = true
{{end}}
{{- if .NodeConfig.AgentConfig.PauseImage }}
  sandbox_image = "{{ .NodeConfig.AgentConfig.PauseImage }}"
{{end}}
{{- if not .NodeConfig.NoFlannel }}
[plugins.cri.cni]
  bin_dir = "{{ .NodeConfig.AgentConfig.CNIBinDir }}"
  conf_dir = "{{ .NodeConfig.AgentConfig.CNIConfDir }}"
{{end}}
[plugins.cri.containerd.runtimes.runc]
  runtime_type = "io.containerd.runc.v2"
{{ if .PrivateRegistryConfig }}
{{ if .PrivateRegistryConfig.Mirrors }}
[plugins.cri.registry.mirrors]{{end}}
{{range $k, $v := .PrivateRegistryConfig.Mirrors }}
[plugins.cri.registry.mirrors."{{$k}}"]
  endpoint = [{{range $i, $j := $v.Endpoints}}{{if $i}}, {{end}}{{printf "%q" .}}{{end}}]
{{end}}
{{range $k, $v := .PrivateRegistryConfig.Configs }}
{{ if $v.Auth }}
[plugins.cri.registry.configs."{{$k}}".auth]
  {{ if $v.Auth.Username }}username = "{{ $v.Auth.Username }}"{{end}}
  {{ if $v.Auth.Password }}password = "{{ $v.Auth.Password }}"{{end}}
  {{ if $v.Auth.Auth }}auth = "{{ $v.Auth.Auth }}"{{end}}
  {{ if $v.Auth.IdentityToken }}identity_token = "{{ $v.Auth.IdentityToken }}"{{end}}
{{end}}
{{ if $v.TLS }}
[plugins.cri.registry.configs."{{$k}}".tls]
  {{ if $v.TLS.CAFile }}ca_file = "{{ $v.TLS.CAFile }}"{{end}}
  {{ if $v.TLS.CertFile }}cert_file = "{{ $v.TLS.CertFile }}"{{end}}
  {{ if $v.TLS.KeyFile }}key_file = "{{ $v.TLS.KeyFile }}"{{end}}
{{end}}
{{end}}
{{end}}
EOF

service k3s start
k3s crictl info

chmod a+r /etc/rancher/k3s/*

# The default storage class with k3s >= 0.10 is "local-path"
#k3s kubectl patch storageclass standard -p "{\"metadata\":{\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}"
k3s kubectl get node
k3s kubectl wait --for=condition=Ready node/ystack-master
';

multipass exec "$VM_NAME" -- sudo cat /etc/rancher/k3s/k3s.yaml \
  | sed "s|127.0.0.1|$K3S_NODEIP_MASTER|" \
  > "$KUBECONFIG.tmp"

KUBECONFIG="$KUBECONFIG.tmp" kubectl config rename-context default ystack-k3s

KUBECONFIG="$KUBECONFIG.tmp" kubectl create namespace ystack

KUBECONFIG="$KUBECONFIG.tmp" kubectl apply -k $YSTACK_HOME/metrics-server

KUBECONFIG="$KUBECONFIG.tmp" y-cluster-install-prometheus-operator

y-kubeconfig-import "$KUBECONFIG.tmp"

echo "# Done. Master IP: $K3S_NODEIP_MASTER. The cluster should be ready for y-stack converge now."
